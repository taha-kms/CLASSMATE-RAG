# Core RAG stack
chromadb-client==0.6.3
rank-bm25>=0.2.2,<0.3
numpy>=1.24,<2.0

# Embeddings: multilingual-e5-base via Sentence-Transformers
sentence-transformers>=2.5.1,<3

# Local LLM runtime: Llama 3.1â€“8B via llama.cpp bindings
llama-cpp-python>=0.2.90,<0.3

# Document loaders / parsing
pypdf>=4.2.0,<5
python-docx>=1.1.2,<1.2
python-pptx>=0.6.23,<1
beautifulsoup4>=4.12.3,<5
lxml>=5.2.1,<6
pdf2image>=1.17.0,<2
markdown>=3.6,<4

# Language detection
langdetect>=1.0.9,<1.1

# CLI / utilities
tqdm>=4.66,<5
pydantic>=2.7,<3

# Model download + env loading
huggingface_hub>=0.23,<1
python-dotenv>=1.0,<2


# NOTE:
# - Torch will be pulled transitively by sentence-transformers. If you need a specific CUDA/CPU build,
#   install it explicitly BEFORE running `pip install -r requirements.txt`.
