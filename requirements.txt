# Core RAG stack
chromadb-client==0.6.3
rank-bm25>=0.2.2,<0.3
numpy>=1.24,<2.0

# Embeddings: multilingual-e5-base via Sentence-Transformers
sentence-transformers>=2.5.1,<3

# Local LLM runtime: Llama 3.1â€“8B via llama.cpp bindings
llama-cpp-python>=0.2.90,<0.3

# Embeddings & ML
torch>=2.0.0 ; platform_system != "Windows" or platform_machine != "ARM64"

# Document loaders / parsing
pypdf>=4.0.0
python-docx>=1.0.0
python-pptx>=0.6.21
beautifulsoup4>=4.12.0
lxml>=4.9.0
markdown>=3.4.0
readability-lxml>=0.8.1
ebooklib>=0.18
pdf2image>=1.16.0
pytesseract>=0.3.10

# Language detection
langdetect>=1.0.9,<1.1

# CLI / utilities
tqdm>=4.66,<5
pydantic>=2.7,<3

# Model download + env loading
huggingface_hub>=0.23,<1
python-dotenv>=1.0,<2
hf_xet

# NOTE:
# - Torch will be pulled transitively by sentence-transformers. If you need a specific CUDA/CPU build,
#   install it explicitly BEFORE running `pip install -r requirements.txt`.
