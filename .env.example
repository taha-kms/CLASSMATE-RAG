# Embedding model (Sentence-Transformers)
EMBEDDING_MODEL_NAME=intfloat/multilingual-e5-base

# LLM backend and model
LLM_BACKEND=llama_cpp

# Hugging Face cache directories
HUGGINGFACE_HUB_CACHE=./models/hf_cache
TRANSFORMERS_CACHE=./models/hf_cache
SENTENCE_TRANSFORMERS_HOME=./models/hf_cache
HF_HOME=./models/hf_cache

# Hugging Face repo and filename to download into ./models/
LLM_REPO_ID=bartowski/Meta-Llama-3.1-8B-Instruct-GGUF
LLM_FILENAME=Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
LLM_MODEL_PATH=./models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

HUGGINGFACE_HUB_CACHE=./models/hf_cache
TRANSFORMERS_CACHE=./models/hf_cache
SENTENCE_TRANSFORMERS_HOME=./models/hf_cache
HF_HOME=./models/hf_cache

# Hugging Face repo and filename to download into ./models/
LLM_REPO_ID=bartowski/Meta-Llama-3.1-8B-Instruct-GGUF
LLM_FILENAME=Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf
LLM_MODEL_PATH=./models/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf

# ChromaDB persistence
CHROMA_PERSIST_DIRECTORY=./indexes/chroma
CHROMA_COLLECTION_NAME=classmate_rag

# Retrieval / chunking defaults
CHUNK_SIZE=1000
CHUNK_OVERLAP=150
K_VECTOR=8
K_BM25=8
USE_HYBRID=true

# Processing toggles
ENABLE_OCR=false
ENABLE_LANGUAGE_DETECTION=true

# Language behavior: default auto-detect; options: en, it, auto
DEFAULT_LANGUAGE=auto

# Logging
LOG_LEVEL=INFO

# ChromaDB HTTP API endpoint
CHROMA_HTTP_URL=http://localhost:8000
